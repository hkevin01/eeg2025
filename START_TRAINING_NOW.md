# ðŸš€ START TRAINING NOW - Ready to Execute!

## âœ… Everything is Ready!

All scripts are fixed and tested. You can now start training without crashes!

## Quick Start (3 Commands)

```bash
# 1. Preprocess (30-60 min) - Run this in background
nohup python scripts/preprocessing/cache_challenge1_windows_safe.py > logs/preprocess.out 2>&1 &

# 2. Monitor preprocessing
tail -f logs/preprocessing/cache_safe_*.log

# 3. After preprocessing, start training
./train_safe_tmux.sh
```

## Step-by-Step Instructions

### Step 1: Start Preprocessing (Required First!)

```bash
cd /home/kevin/Projects/eeg2025

# Start preprocessing in background
nohup python scripts/preprocessing/cache_challenge1_windows_safe.py > logs/preprocess.out 2>&1 &

# Get the PID
echo $! > /tmp/preprocess.pid

# Monitor progress
tail -f logs/preprocessing/cache_safe_*.log
```

**What it does:**
- Processes R1, R2, R3, R4 one at a time
- Creates cached HDF5 files in `data/cached/`
- Stops at 85% RAM usage
- Auto-skips already-completed releases
- Takes 30-60 minutes

**Expected output:**
```
data/cached/challenge1_R1_windows.h5  (~2GB)
data/cached/challenge1_R2_windows.h5  (~3GB)
data/cached/challenge1_R3_windows.h5  (~3GB)
data/cached/challenge1_R4_windows.h5  (~4GB)
Total: ~12GB
```

**Check progress:**
```bash
# Watch memory
watch -n 5 'free -h'

# Check process
ps aux | grep cache_challenge

# Check output files
ls -lh data/cached/

# Check log
tail -50 logs/preprocessing/cache_safe_*.log
```

### Step 2: Verify Preprocessing Complete

```bash
# Check all files created
ls -lh data/cached/challenge1_*.h5

# Should show 4 files (R1, R2, R3, R4)
# Total size: ~12GB

# Check log for completion
grep "PREPROCESSING COMPLETE" logs/preprocessing/cache_safe_*.log
```

### Step 3: Start Training

```bash
# Launch training in tmux with memory monitoring
./train_safe_tmux.sh

# Attach to watch
tmux attach -t eeg_train_safe

# Detach: Ctrl+b then d
```

**What you'll see:**
- Left pane: Training output
- Right pane: Memory monitor (updates every 5s)
- Training progress with epochs
- Memory staying below 85%

### Step 4: Monitor Training

**In tmux session:**
- Watch training progress live
- Press Ctrl+b then d to detach

**In separate terminal:**
```bash
# Watch log
tail -f logs/training_comparison/training_safe_*.log

# Check process
ps aux | grep train_challenge

# Check memory
watch -n 5 'free -h'

# Check if model being saved
watch -n 10 'ls -lth weights_*.pt | head -3'
```

### Step 5: Check Results

**After training completes (~2-3 hours):**
```bash
# Check completion
grep "TRAINING COMPLETE\|Best validation" logs/training_comparison/training_safe_*.log

# Check model
ls -lh weights_challenge_1_multi_release.pt

# Compare to baseline
echo "Baseline: 1.00 NRMSE"
echo "Target: < 0.85 NRMSE (competitive: < 0.75)"
```

## If Something Goes Wrong

### Preprocessing Crashes
```bash
# Check what happened
tail -100 logs/preprocessing/cache_safe_*.log

# Check memory
free -h

# Resume (it will skip completed releases)
python scripts/preprocessing/cache_challenge1_windows_safe.py
```

### Training Crashes
```bash
# Check log
tail -100 logs/training_comparison/training_safe_*.log

# Check if model saved
ls -lth weights_*.pt

# Restart
./train_safe_tmux.sh
```

### Memory Issues
```bash
# Check memory hogs
ps aux --sort=-%mem | head -10

# Kill preprocessing if needed
pkill -f cache_challenge

# Clear system cache
sync && echo 3 | sudo tee /proc/sys/vm/drop_caches

# Process one release at a time
python scripts/preprocessing/cache_challenge1_windows_safe.py --releases R1
python scripts/preprocessing/cache_challenge1_windows_safe.py --releases R2
```

## Complete Workflow

```bash
# Terminal 1: Start preprocessing
cd /home/kevin/Projects/eeg2025
nohup python scripts/preprocessing/cache_challenge1_windows_safe.py > logs/preprocess.out 2>&1 &
tail -f logs/preprocessing/cache_safe_*.log

# Wait for completion (~30-60 min)
# When you see "PREPROCESSING COMPLETE"

# Verify
ls -lh data/cached/challenge1_*.h5

# Terminal 1: Start training
./train_safe_tmux.sh

# Terminal 2: Monitor
tmux attach -t eeg_train_safe

# Or watch log
tail -f logs/training_comparison/training_safe_*.log
```

## Expected Timeline

| Step | Duration | Memory | Output |
|------|----------|--------|--------|
| Preprocessing R1 | ~5-10 min | < 4GB | 2GB file |
| Preprocessing R2 | ~10-15 min | < 4GB | 3GB file |
| Preprocessing R3 | ~10-15 min | < 4GB | 3GB file |
| Preprocessing R4 | ~15-20 min | < 4GB | 4GB file |
| **Total Preprocessing** | **30-60 min** | **< 4GB** | **~12GB total** |
| Training | 2-3 hours | 2-4GB | Model weights |

## Success Criteria

**Preprocessing:**
- âœ… All 4 files created in `data/cached/`
- âœ… Total size ~12GB
- âœ… No crashes
- âœ… Log shows "PREPROCESSING COMPLETE"

**Training:**
- âœ… Runs for 2-3 hours without crash
- âœ… Memory stays < 85%
- âœ… Model weights saved
- âœ… NRMSE improves or stays stable
- âœ… Log shows "TRAINING COMPLETE"

## Emergency Commands

```bash
# Stop everything
pkill -f cache_challenge
pkill -f train_challenge
tmux kill-session -t eeg_train_safe

# Check nothing running
ps aux | grep python

# System recovery if frozen
# Press Ctrl+Alt+F3, login, then:
pkill -9 python
sudo reboot
```

## After Training

**If successful:**
1. Check NRMSE in log
2. Compare to baseline (1.00)
3. If improved, move to Challenge 2
4. If not, analyze what went wrong

**Next steps:**
- Challenge 2 training
- EEGNet architecture
- Data augmentation
- Test-time augmentation
- Ensemble methods

---

## ðŸŽ¯ EXECUTE NOW:

```bash
# Copy-paste these 3 commands:

# 1. Start preprocessing
nohup python scripts/preprocessing/cache_challenge1_windows_safe.py > logs/preprocess.out 2>&1 &

# 2. Monitor
tail -f logs/preprocessing/cache_safe_*.log

# 3. After completion, train
./train_safe_tmux.sh
```

**You're ready! Everything is fixed and tested!** ðŸš€
