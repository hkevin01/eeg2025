#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Unified GPU Testing
===========================

Comprehensive testing for CUDA/ROCm unified optimization with detailed debugging.
"""

import sys
import os
import time
import signal
import torch
import numpy as np
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def timeout_handler(signum, frame):
    """Handle timeout for GPU operations"""
    print("\n‚ö†Ô∏è  TIMEOUT: GPU operation taking too long - cleaning up...")
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    sys.exit(1)

def print_separator(title):
    """Print a nice separator"""
    print("\n" + "="*80)
    print(f"üîç {title}")
    print("="*80)

def test_platform_detection():
    """Test platform detection in detail"""
    print_separator("PLATFORM DETECTION")

    try:
        from gpu.unified_gpu_optimized import GPUPlatformDetector

        detector = GPUPlatformDetector()
        info = detector.get_info()

        print(f"‚úÖ Module import successful")
        print(f"üìä Platform Information:")
        print(f"   GPU Available: {info['gpu_available']}")

        if info['gpu_available']:
            print(f"   Vendor: {info['vendor']}")
            print(f"   Platform: {info['platform']}")
            print(f"   Version: {info['version']}")
            print(f"   Device: {info['device_name']}")

            # Additional PyTorch info
            print(f"\nüîß PyTorch Configuration:")
            print(f"   PyTorch Version: {torch.__version__}")
            print(f"   CUDA Available: {torch.cuda.is_available()}")
            print(f"   Device Count: {torch.cuda.device_count()}")

            if hasattr(torch.version, 'hip'):
                print(f"   ROCm/HIP Version: {torch.version.hip}")
            if torch.version.cuda:
                print(f"   CUDA Version: {torch.version.cuda}")

            # Memory info
            if torch.cuda.is_available():
                device = torch.cuda.current_device()
                total_mem = torch.cuda.get_device_properties(device).total_memory / 1024**3
                print(f"   GPU Memory: {total_mem:.1f} GB")

        return detector

    except Exception as e:
        print(f"‚ùå Platform detection failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_basic_operations(detector):
    """Test basic GPU operations"""
    print_separator("BASIC GPU OPERATIONS")

    if not detector or not detector.gpu_available:
        print("‚ö†Ô∏è  GPU not available - skipping GPU tests")
        return

    try:
        device = torch.device('cuda')

        # Test basic tensor operations
        print("üîß Testing basic tensor operations...")
        x_cpu = torch.randn(100, 100)
        print(f"   CPU tensor created: {x_cpu.shape}")

        x_gpu = x_cpu.to(device)
        print(f"   Moved to GPU: {x_gpu.device}")

        # Basic computation
        result = torch.matmul(x_gpu, x_gpu.t())
        print(f"   Matrix multiplication result: {result.shape}")

        # Move back to CPU
        result_cpu = result.cpu()
        print(f"   Moved back to CPU: {result_cpu.shape}")

        # Cleanup
        del x_gpu, result
        torch.cuda.empty_cache()
        print("   ‚úÖ Basic operations successful")

    except Exception as e:
        print(f"   ‚ùå Basic operations failed: {e}")

def test_fft_operations(detector):
    """Test FFT operations"""
    print_separator("FFT OPERATIONS")

    if not detector or not detector.gpu_available:
        print("‚ö†Ô∏è  GPU not available - testing CPU FFT only")

        # CPU FFT test
        x = torch.randn(16, 64, 1000)
        print(f"   CPU input shape: {x.shape}")

        X = torch.fft.rfft(x, dim=-1)
        print(f"   CPU FFT result: {X.shape}")

        x_reconstructed = torch.fft.irfft(X, dim=-1)
        print(f"   CPU iFFT result: {x_reconstructed.shape}")

        error = torch.mean(torch.abs(x - x_reconstructed[:, :, :x.shape[-1]]))
        print(f"   CPU reconstruction error: {error:.6f}")
        return

    try:
        from gpu.unified_gpu_optimized import UnifiedFFTOptimizer

        fft_opt = UnifiedFFTOptimizer()
        print(f"   Using platform: {detector.platform}")

        # Small test for safety
        x = torch.randn(8, 32, 500)  # Smaller size for AMD stability
        print(f"   Input shape: {x.shape}")

        # Test FFT
        print("   Computing FFT...")
        X = fft_opt.rfft_batch(x, dim=-1)
        print(f"   FFT result shape: {X.shape}")

        # Test inverse FFT with timeout and debugging
        print("   Computing inverse FFT...")
        print(f"   FFT tensor info: shape={X.shape}, dtype={X.dtype}, device={X.device}")
        print(f"   Memory before iFFT: {torch.cuda.memory_allocated()/1024**2:.1f}MB")

        try:
            # AMD GPU often hangs on iFFT - use timeout
            import threading
            import queue

            # Store variables for thread access
            X_for_thread = X
            x_for_thread = x
            fft_opt_for_thread = fft_opt

            result_queue = queue.Queue()
            error_queue = queue.Queue()

            def ifft_worker():
                try:
                    print("     Starting GPU iFFT computation...")
                    result = fft_opt_for_thread.irfft_batch(X_for_thread, n=x_for_thread.shape[-1], dim=-1)
                    result_queue.put(result)
                    print("     GPU iFFT completed successfully")
                except Exception as e:
                    print(f"     GPU iFFT error: {e}")
                    error_queue.put(str(e))

            print("   Starting iFFT thread...")
            thread = threading.Thread(target=ifft_worker)
            thread.start()
            thread.join(timeout=10)  # 10 second timeout

            if thread.is_alive():
                print("   ‚ö†Ô∏è  GPU iFFT timed out after 10 seconds - known AMD ROCm issue")
                print("   Force terminating thread and using CPU fallback...")

                # CPU fallback
                X_cpu = X.cpu()
                x_cpu = x.cpu()
                x_reconstructed = torch.fft.irfft(X_cpu, n=x_cpu.shape[-1], dim=-1)
                print(f"   CPU iFFT result shape: {x_reconstructed.shape}")

                # Verify reconstruction on CPU
                original_len = x_cpu.shape[-1]
                reconstructed_len = x_reconstructed.shape[-1]
                min_len = min(original_len, reconstructed_len)

                error = torch.mean(torch.abs(x_cpu[:, :, :min_len] - x_reconstructed[:, :, :min_len]))
                print(f"   CPU reconstruction error: {error:.6f}")
                print("   ‚úÖ FFT operations successful (CPU fallback due to AMD timeout)")

            else:
                # Thread completed - check for results
                if not result_queue.empty():
                    x_reconstructed = result_queue.get()
                    print(f"   GPU iFFT result shape: {x_reconstructed.shape}")

                    # Verify reconstruction
                    original_len = x.shape[-1]
                    reconstructed_len = x_reconstructed.shape[-1]
                    min_len = min(original_len, reconstructed_len)

                    error = torch.mean(torch.abs(x[:, :, :min_len] - x_reconstructed[:, :, :min_len]))
                    print(f"   GPU reconstruction error: {error:.6f}")

                    if error < 1e-4:
                        print("   ‚úÖ FFT operations successful (full GPU)")
                    else:
                        print("   ‚ö†Ô∏è  FFT operations completed but with high error")

                elif not error_queue.empty():
                    error_msg = error_queue.get()
                    print(f"   ‚ö†Ô∏è  GPU iFFT failed: {error_msg}")
                    print("   Using CPU fallback...")

                    # CPU fallback
                    X_cpu = X.cpu()
                    x_cpu = x.cpu()
                    x_reconstructed = torch.fft.irfft(X_cpu, n=x_cpu.shape[-1], dim=-1)
                    print(f"   CPU fallback result: {x_reconstructed.shape}")
                    print("   ‚úÖ FFT operations successful (CPU fallback)")
                else:
                    print("   ‚ö†Ô∏è  No result from GPU iFFT thread")

        except Exception as e:
            print(f"   ‚ùå iFFT thread setup failed: {e}")
            print("   Using direct CPU fallback...")

            # Direct CPU fallback for any error
            X_cpu = X.cpu()
            x_cpu = x.cpu()
            x_reconstructed = torch.fft.irfft(X_cpu, n=x_cpu.shape[-1], dim=-1)
            print(f"   CPU direct fallback result: {x_reconstructed.shape}")
            print("   ‚úÖ FFT operations successful (direct CPU fallback)")

        print(f"   Memory after iFFT: {torch.cuda.memory_allocated()/1024**2:.1f}MB")

        # Cleanup
        del x, X, x_reconstructed
        torch.cuda.empty_cache()

    except Exception as e:
        print(f"   ‚ùå FFT operations failed: {e}")
        import traceback
        traceback.print_exc()

def test_blas_operations(detector):
    """Test BLAS operations"""
    print_separator("BLAS OPERATIONS")

    if not detector or not detector.gpu_available:
        print("‚ö†Ô∏è  GPU not available - testing CPU BLAS only")

        # CPU BLAS test
        a = torch.randn(16, 64, 32)
        b = torch.randn(16, 32, 64)
        c = torch.bmm(a, b)
        print(f"   CPU batch matmul: {a.shape} x {b.shape} = {c.shape}")
        return

    try:
        from gpu.unified_gpu_optimized import UnifiedBLASOptimizer

        blas_opt = UnifiedBLASOptimizer()
        print(f"   Using platform: {detector.platform}")

        # Test batch matrix multiplication
        a = torch.randn(8, 32, 64)  # Smaller for safety
        b = torch.randn(8, 64, 32)

        print(f"   Input shapes: {a.shape} x {b.shape}")

        c = blas_opt.bmm_optimized(a, b)
        print(f"   Result shape: {c.shape}")

        # Verify with CPU
        a_cpu = a.cpu()
        b_cpu = b.cpu()
        c_cpu = torch.bmm(a_cpu, b_cpu)
        c_from_gpu = c.cpu() if c.is_cuda else c

        error = torch.mean(torch.abs(c_cpu - c_from_gpu))
        print(f"   GPU vs CPU error: {error:.6f}")

        if error < 1e-4:
            print("   ‚úÖ BLAS operations successful")
        else:
            print("   ‚ö†Ô∏è  BLAS operations completed but with high error")

        # Cleanup
        del a, b, c, a_cpu, b_cpu, c_cpu, c_from_gpu
        torch.cuda.empty_cache()

    except Exception as e:
        print(f"   ‚ùå BLAS operations failed: {e}")
        import traceback
        traceback.print_exc()

def test_memory_management(detector):
    """Test GPU memory management"""
    print_separator("MEMORY MANAGEMENT")

    if not detector or not detector.gpu_available:
        print("‚ö†Ô∏è  GPU not available - skipping memory tests")
        return

    try:
        print("   Testing memory allocation and cleanup...")

        # Initial memory state
        torch.cuda.empty_cache()
        initial_allocated = torch.cuda.memory_allocated() / 1024**2
        initial_cached = torch.cuda.memory_reserved() / 1024**2

        print(f"   Initial - Allocated: {initial_allocated:.1f}MB, Cached: {initial_cached:.1f}MB")

        # Allocate some memory
        tensors = []
        for i in range(5):
            tensor = torch.randn(100, 100, device='cuda')
            tensors.append(tensor)

        allocated = torch.cuda.memory_allocated() / 1024**2
        cached = torch.cuda.memory_reserved() / 1024**2
        print(f"   After allocation - Allocated: {allocated:.1f}MB, Cached: {cached:.1f}MB")

        # Clean up
        del tensors
        torch.cuda.empty_cache()

        final_allocated = torch.cuda.memory_allocated() / 1024**2
        final_cached = torch.cuda.memory_reserved() / 1024**2
        print(f"   After cleanup - Allocated: {final_allocated:.1f}MB, Cached: {final_cached:.1f}MB")

        print("   ‚úÖ Memory management successful")

    except Exception as e:
        print(f"   ‚ùå Memory management failed: {e}")

def benchmark_performance(detector):
    """Quick performance benchmark"""
    print_separator("PERFORMANCE BENCHMARK")

    if not detector or not detector.gpu_available:
        print("‚ö†Ô∏è  GPU not available - CPU benchmark only")

        # CPU benchmark
        x = torch.randn(32, 129, 1000)
        start = time.time()
        for _ in range(10):
            _ = torch.fft.rfft(x, dim=-1)
        cpu_time = (time.time() - start) / 10
        print(f"   CPU FFT time: {cpu_time*1000:.2f} ms")
        return

    try:
        from gpu.unified_gpu_optimized import UnifiedFFTOptimizer

        fft_opt = UnifiedFFTOptimizer()

        # Small benchmark for safety
        x_cpu = torch.randn(16, 64, 1000)
        x_gpu = x_cpu.cuda()

        # CPU benchmark
        start = time.time()
        for _ in range(10):
            _ = torch.fft.rfft(x_cpu, dim=-1)
        cpu_time = (time.time() - start) / 10

        # GPU warmup
        for _ in range(3):
            _ = fft_opt.rfft_batch(x_gpu, dim=-1)
        torch.cuda.synchronize()

        # GPU benchmark
        start = time.time()
        for _ in range(10):
            _ = fft_opt.rfft_batch(x_gpu, dim=-1)
        torch.cuda.synchronize()
        gpu_time = (time.time() - start) / 10

        speedup = cpu_time / gpu_time
        print(f"   CPU FFT time: {cpu_time*1000:.2f} ms")
        print(f"   {detector.platform} FFT time: {gpu_time*1000:.2f} ms")
        print(f"   üöÄ Speedup: {speedup:.2f}x")

        # Cleanup
        del x_cpu, x_gpu
        torch.cuda.empty_cache()

    except Exception as e:
        print(f"   ‚ùå Benchmark failed: {e}")

def main():
    """Main test runner"""
    print("üöÄ Enhanced Unified GPU Testing")
    print("="*80)

    # Set timeout for safety (60 seconds total)
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(60)

    try:
        # Run all tests
        detector = test_platform_detection()
        test_basic_operations(detector)
        test_fft_operations(detector)
        test_blas_operations(detector)
        test_memory_management(detector)
        benchmark_performance(detector)

        print_separator("TEST SUMMARY")
        if detector and detector.gpu_available:
            print(f"‚úÖ All tests completed successfully!")
            print(f"üéØ Platform: {detector.vendor} {detector.platform}")
            print(f"üîß Device: {detector.device_name}")
        else:
            print("‚úÖ CPU tests completed successfully!")
            print("‚ö†Ô∏è  GPU not available or tests skipped")

    except KeyboardInterrupt:
        print("\nüõë Tests interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Tests failed with error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Always cleanup
        signal.alarm(0)  # Cancel timeout
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print("\nüîí Tests completed safely")

if __name__ == "__main__":
    main()
