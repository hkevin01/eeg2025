# ğŸ† NeurIPS 2025 EEG Foundation Challenge - Competition Focus

**Date:** October 17, 2025  
**Deadline:** November 2, 2025 (16 days remaining)  
**Competition:** https://eeg2025.github.io  
**Codabench:** https://www.codabench.org/competitions/4287/

---

## ğŸ¯ THE TWO CHALLENGES

### Challenge 1: Cross-Task Transfer Learning
**Goal:** Develop models that effectively transfer knowledge from passive EEG tasks to active cognitive tasks

**Task:** Contrast Change Detection (CCD)
- **Input:** EEG data (129 channels, 2 seconds @ 100 Hz)
- **Output:** Predict response time (regression)
- **Data:** Releases R1-R5 (train on R1-R4, validate on R5)

**Key Points:**
- Pre-train on passive tasks (RestingState, DespicableMe, etc.)
- Fine-tune on active task (contrastChangeDetection)
- Predict: How long does it take the subject to respond?
- Evaluation: Pearson correlation + accuracy metrics

**Current Status:**
- âœ… Training TCN model on R1, R2, R3 â†’ Validate on R4
- ğŸ”„ Currently running (PID: 105017, 78% CPU)
- ğŸ“Š Processing 3,786 windows from competition data

### Challenge 2: Externalizing Factor Prediction
**Goal:** Predict externalizing factor from EEG to enable objective mental health assessments

**Task:** Regression of externalizing factor (mental health measure)
- **Input:** EEG data from any task
- **Output:** Predict p_factor score
- **Data:** Releases R2, R3, R4 (train), R5 (validate)

**Key Points:**
- Externalizing factor from Child Behavior Checklist (CBCL)
- Learn physiologically meaningful representations
- Robust out-of-distribution generalization
- May use self-supervised learning (e.g., Relative Positioning)

---

## ğŸ“Š COMPETITION DATA STRUCTURE

### Releases (R1-R5)
```
R1, R2, R3 â†’ Training data
R4 â†’ Validation data  
R5 â†’ Test data (for submission evaluation)
```

### Tasks Available
1. **contrastChangeDetection** (CCD) - Challenge 1 target task
2. **RestingState** - Passive, good for pre-training
3. **DespicableMe** - Passive video watching
4. **ThePresent** - Passive video watching
5. **FunwithFractals** - Passive visual stimuli
6. **surroundSupp** - Visual task
7. **seqLearning8target** - Sequential learning

### Data Format
- **EEG:** 129 channels, various sampling rates (downsampled to 100 Hz)
- **Format:** BDF files (Biosemi Data Format)
- **Preprocessing:** Handled by `eegdash` and `braindecode`
- **Metadata:** Subject, session, age, gender, p_factor, etc.

---

## ğŸš€ CURRENT TRAINING STATUS

### What's Running Right Now
```bash
Process: python3 train_tcn_competition_data.py
PID: 105017
CPU: 78.4%
Time: Running for 45 seconds
Status: Loading and preprocessing competition data
```

### Training Configuration
```python
Model: TCN (Temporal Convolutional Network)
  - Architecture: 196K parameters
  - Filters: 48
  - Kernel: 7
  - Levels: 5
  - Dropout: 0.3

Data:
  - Train: R1, R2, R3 (contrastChangeDetection)
  - Val: R4 (contrastChangeDetection)
  - Task: Predict response time
  - Max datasets: 50 per release (for faster iteration)

Training:
  - Optimizer: AdamW (lr=0.001, wd=0.0001)
  - Scheduler: CosineAnnealingWarmRestarts
  - Batch size: 16 (effective 32 with accumulation)
  - Epochs: 100 (patience=15)
  - Device: CPU (stable, survives crashes)
```

### Crash-Proof System
âœ… **Running with nohup** - Survives VS Code crashes  
âœ… **Running in background** - Survives terminal closure  
âœ… **Automatic checkpointing** - Saves every 5 epochs  
âœ… **Early stopping** - Prevents overfitting  
âœ… **Signal handling** - Graceful shutdown on SIGINT/SIGTERM  

---

## ğŸ“ˆ WHAT WE'RE TRAINING FOR

### Challenge 1: Response Time Prediction

**Pipeline:**
1. **Load competition data** (R1-R3 for training)
   - Task: contrastChangeDetection
   - Extract trials with stimulus + response
   
2. **Preprocessing:**
   - Annotate trials with response times
   - Create 2-second windows starting 0.5s after stimulus
   - Normalize EEG data (channel-wise z-score)
   
3. **Model Training:**
   - TCN processes temporal patterns
   - Predicts continuous response time value
   - Optimizes MSE loss
   
4. **Validation:**
   - Test on R4 data
   - Compute validation loss
   - Early stopping when no improvement
   
5. **Submission:**
   - Load best checkpoint
   - Predict on R5 test data
   - Submit to Codabench

### Challenge 2: Externalizing Factor (Next)

**Pipeline (to implement):**
1. Load multi-task data (RestingState + others)
2. Create fixed-length windows
3. Train regression model for p_factor
4. Validate on R5
5. Submit to Codabench

---

## ğŸ¯ KEY COMPETITION REQUIREMENTS

### Submission Format
```python
# submission.py must contain:

class Challenge1Model:
    def __init__(self):
        # Load your trained model
        pass
    
    def __call__(self, X):
        # X: (batch, channels, time)
        # Return: (batch, 1) response times
        pass

class Challenge2Model:
    def __init__(self):
        # Load your trained model
        pass
    
    def __call__(self, X):
        # X: (batch, channels, time)
        # Return: (batch, 1) p_factor scores
        pass
```

### File Size Limits
- **Maximum submission size:** 50 MB
- **Our current models:**
  - TCN: 2.4 MB âœ…
  - With TTA: 9.3 MB âœ…
  - Plenty of room for improvement!

### Evaluation Metrics

**Challenge 1:**
- Pearson correlation (response time prediction)
- Success rate accuracy (optional)
- Combined metric (weighted)

**Challenge 2:**
- Mean Absolute Error (MAE)
- Pearson correlation
- Out-of-distribution generalization

---

## ğŸ”„ TRAINING WORKFLOW (Current)

### Step 1: Data Loading âœ… IN PROGRESS
```
ğŸ“¦ Processing release: R1
   Found 1,328 datasets
   Limited to 50 datasets
   Valid datasets: 45
   Preprocessing...
   Creating windows...
   Total windows: 1,262
   âœ… Extracted samples from R1
```

### Step 2: Training (Next)
- Will train for up to 100 epochs
- Early stopping after 15 epochs without improvement
- Save checkpoints every 5 epochs
- Save best model based on validation loss

### Step 3: Integration (After Training)
- Load best checkpoint
- Integrate into submission.py
- Replace current Challenge1Model
- Test locally with local_scoring.py
- Create new submission ZIP

### Step 4: Submission (Final)
- Upload to Codabench
- Wait for test results (1-2 hours)
- Compare with current score (0.2832 NRMSE)
- Iterate if needed

---

## ğŸ“ FILES IN COMPETITION SUBMISSION

### Current Submission (v5)
```
eeg2025_submission_tta_v5.zip (9.3 MB)
â”œâ”€â”€ submission.py                           # 8.2 KB - Main entry point
â”œâ”€â”€ submission_base.py                      # 11.8 KB - Base models
â”œâ”€â”€ response_time_attention.pth             # 9.8 MB - Challenge 1 model
â””â”€â”€ weights_challenge_2_multi_release.pt    # 261 KB - Challenge 2 model
```

### Next Submission (v6) - PLAN
```
eeg2025_submission_tcn_v6.zip
â”œâ”€â”€ submission.py                           # Updated with TCN
â”œâ”€â”€ submission_base.py                      # Keep TTA integration
â”œâ”€â”€ challenge1_tcn_competition_best.pth     # 2.4 MB - NEW TCN model
â”œâ”€â”€ weights_challenge_2_multi_release.pt    # 261 KB - Keep current
â””â”€â”€ tta_predictor.py                        # Optional TTA wrapper
```

---

## ğŸ“ LESSONS FROM STARTER KIT

### Challenge 1 Starter Kit Teaches:
1. âœ… Load data with EEGChallengeDataset
2. âœ… Annotate trials with response times
3. âœ… Create stimulus-locked windows
4. âœ… Build regression models
5. âœ… Train/val/test split by subject
6. âœ… Evaluate with RMSE and correlation

### Challenge 2 Starter Kit Teaches:
1. Load multi-task data
2. Extract p_factor from metadata
3. Create fixed-length windows
4. Handle regression with continuous targets
5. Emphasize generalization

### We're Following Best Practices:
- âœ… Using official EEGChallengeDataset loader
- âœ… Using official preprocessing (annotate_trials_with_target)
- âœ… Using official windowing (create_windows_from_events)
- âœ… Training on R1-R3, validating on R4
- âœ… Will test on R5 via submission
- âœ… Using braindecode-compatible models

---

## ğŸš¨ CRITICAL COMPETITION RULES

### Must Use Official Tools
- âœ… `eegdash.EEGChallengeDataset` for data loading
- âœ… `braindecode` for preprocessing
- âœ… Official annotations (annotate_trials_with_target)
- âœ… Official windowing (create_windows_from_events)

### Must Follow Data Splits
- âœ… Train on R1, R2, R3
- âœ… Validate on R4
- âœ… Test on R5 (via submission only)
- âŒ NEVER train on R5 (that's cheating!)

### Must Meet Technical Requirements
- âœ… Python 3.12 compatible
- âœ… PyTorch models
- âœ… Under 50 MB submission size
- âœ… GPU and CPU compatible
- âœ… No external data dependencies

---

## ğŸ“Š CURRENT COMPETITION STANDING

### Our Submissions
| Version | Date | Challenge 1 | Challenge 2 | Combined | Rank |
|---------|------|-------------|-------------|----------|------|
| v1 | Oct 14 | 2.013 | - | 2.013 | #47 |
| v5 | Ready | TTA (exp: 0.25) | Current | 0.25-0.26 | Est: Top 15 |
| v6 | Training | TCN (exp: 0.21) | Current | 0.21-0.22 | Est: Top 5 |

### Target Metrics
- **Current:** 0.2832 NRMSE
- **Top 10:** ~0.20 NRMSE
- **Top 3:** ~0.16-0.18 NRMSE
- **Target:** <0.16 NRMSE for #1 ğŸ†

---

## ğŸ”¥ NEXT ACTIONS

### Immediate (Today)
1. âœ… Wait for TCN training to complete (~1-2 hours)
2. â¬œ Evaluate TCN on R4 validation set
3. â¬œ If good, integrate into submission.py
4. â¬œ Test locally with local_scoring.py
5. â¬œ Create v6 submission ZIP
6. â¬œ Upload v6 to Codabench

### Short-term (This Week)
1. â¬œ Implement Challenge 2 TCN training
2. â¬œ Train on multi-task data for p_factor
3. â¬œ Create v7 with improved Challenge 2
4. â¬œ Test S4 State Space Model
5. â¬œ Implement ensemble of TCN + S4

### Medium-term (Next Week)
1. â¬œ Pre-training on passive tasks
2. â¬œ Fine-tuning on active tasks
3. â¬œ Advanced augmentation strategies
4. â¬œ Hyperparameter optimization
5. â¬œ Multiple submissions for A/B testing

### Before Deadline (Nov 2)
1. â¬œ Super-ensemble of all best models
2. â¬œ Optimize TTA parameters
3. â¬œ Final hyperparameter sweep
4. â¬œ Last-minute improvements
5. â¬œ Submit final version

---

## ğŸ’¡ KEY INSIGHTS

### What Makes This Competition Unique
1. **Transfer Learning Focus:** Not just accuracy, but transferability
2. **Real-World Data:** Noisy, variable, real children's EEG
3. **Generalization:** Must work on unseen subjects and sites
4. **Open Source:** Community-driven, collaborative
5. **Clinical Relevance:** Actual mental health applications

### Our Strategy
1. **Start Simple:** Basic TCN working first âœ…
2. **Validate Everything:** Always test on R4 before submission
3. **Iterate Fast:** Small improvements compound
4. **Use Official Tools:** Don't reinvent the wheel
5. **Focus on Competition Goals:** Response time + p_factor

### What's Working
- âœ… Crash-proof training system
- âœ… Following official starter kit patterns
- âœ… Using competition data correctly (R1-R4)
- âœ… TCN architecture validated
- âœ… Clear path to submission

### What's Next
- Train on FULL datasets (not mini, not limited to 50)
- Implement pre-training on passive tasks
- Add Challenge 2 training
- Create ensemble models
- Optimize for competition metrics

---

## ğŸ¯ SUCCESS CRITERIA

### Minimum Success (Baseline)
- âœ… TCN trains without crashing
- âœ… Validation loss decreases
- â¬œ Submission format correct
- â¬œ Better than v1 score (2.013)

### Good Success (Top 15)
- â¬œ TCN+TTA submission uploaded
- â¬œ Score: 0.25-0.26 NRMSE
- â¬œ Both challenges working
- â¬œ Rank improvement visible

### Excellent Success (Top 5)
- â¬œ Advanced models (S4, ensemble)
- â¬œ Score: 0.20-0.22 NRMSE
- â¬œ Transfer learning working
- â¬œ Pre-training + fine-tuning

### Perfect Success (Top 3)
- â¬œ Super-ensemble
- â¬œ Score: <0.18 NRMSE
- â¬œ Novel architecture insights
- â¬œ Reproducible code shared

---

## ğŸ”„ MONITORING COMMANDS

```bash
# Check training status
./scripts/monitor_training.sh

# Watch live training log
tail -f logs/train_real_*.log

# Check for new checkpoints
ls -lht checkpoints/challenge1_tcn_competition*.pth

# View training history
cat checkpoints/challenge1_tcn_competition_history.json

# Check process is running
ps aux | grep train_tcn_competition

# Stop training (if needed)
kill <PID>
```

---

**Last Updated:** October 17, 2025, 18:21  
**Status:** âœ… Training on competition data (R1-R3 â†’ R4)  
**Next Milestone:** Complete TCN training, create v6 submission  
**Days to Deadline:** 16 days
