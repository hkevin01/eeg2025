# EEG2025 Competition - Phase 2 TODO List
## Updated: October 24, 2025 17:05 UTC

---

## üéØ Current Status: TRAINING IN TMUX (CRASH-PROOF)

**Tmux Session:** `eeg_training`  
**Experiment:** `experiments/sam_full_run/20251024_165931/`  
**Status:** üîÑ Data Loading (334 subjects)  
**Expected Completion:** Tonight or tomorrow morning  

---

## Phase 2A: Crash Recovery & Tmux Setup ‚úÖ COMPLETE

```markdown
- [x] Recover from 1st VSCode crash
- [x] Restart training with nohup
- [x] Recover from 2nd VSCode crash
- [x] Implement tmux-based solution
- [x] Create start_training_tmux.sh
- [x] Create monitor_training.sh
- [x] Launch training in tmux
- [x] Verify tmux session active
- [x] Create TMUX_TRAINING_STATUS.md documentation
```

**Status:** ‚úÖ All items complete  
**Outcome:** Training now crash-resistant in tmux session  
**Next:** Wait for data loading to complete

---

## Phase 2B: Data Loading & Training üîÑ IN PROGRESS

```markdown
- [x] Start data loading (334 subjects)
- [ ] üîÑ Wait for data loading complete (~5-10 min)
  - Current: Loading ds005506-bdf (150) + ds005507-bdf (184)
  - Expected: ~1000-2000 windows total
- [ ] First epoch starts
  - Subject-level CV split
  - Model creation (EEGNeX, 62K params)
  - SAM optimizer init
- [ ] Monitor epoch progress (100 epochs)
  - Watch NRMSE improvement
  - GPU utilization ~3-4 GB
  - Learning rate adjustments
- [ ] Early stopping triggered (~epoch 40-60)
- [ ] Best model saved
```

**Status:** üîÑ Data loading in progress  
**ETA:** Data load complete in ~5 min, training complete in ~3 hours  
**Next Check:** In 30 minutes

---

## Phase 2C: Results Analysis ‚è≥ PENDING

```markdown
- [ ] Training completes
- [ ] Check final NRMSE
  - tail -100 training_tmux.log | grep "Best Val NRMSE"
- [ ] Load best model checkpoint
  - experiments/sam_full_run/*/checkpoints/best_model.pt
- [ ] Analyze training curves
  - Loss over epochs
  - NRMSE over epochs
  - Learning rate schedule
- [ ] Compare with baselines
  - Test run: NRMSE 0.3206 (2 epochs, 6 subjects)
  - Oct 16: NRMSE 1.002 (Challenge 1)
  - Expected: < 0.25 validation NRMSE
```

**Status:** ‚è≥ Waiting for training completion  
**Depends On:** Phase 2B completion  
**Success Criteria:** Val NRMSE < 0.30

---

## Phase 2D: Submission Creation ‚è≥ CONDITIONAL

**Condition:** Only if Validation NRMSE < 1.0

```markdown
- [ ] Copy best model to weights/
  - cp best_model.pt weights_challenge_1_sam.pt
- [ ] Update submission.py
  - Load SAM weights
  - Verify prediction code
- [ ] Test submission locally
  - python submission.py --local-test
- [ ] Package submission
  - python scripts/create_submission_package.py
- [ ] Upload to Codabench
- [ ] Verify leaderboard score
```

**Status:** ‚è≥ Conditional on Phase 2C results  
**Target Score:** Challenge 1 NRMSE < 1.0  
**Stretch Goal:** Challenge 1 NRMSE < 0.8 (beat Oct 16)

---

## Phase 3: Advanced Models (Weekend) ‚è≥ FUTURE

```markdown
- [ ] Implement Conformer architecture
  - CNN stem + Transformer encoder
  - src/models/advanced/conformer.py
- [ ] Train Conformer on Challenge 1
  - Same data pipeline as Phase 2
  - 100 epochs with SAM
- [ ] Compare performance
  - EEGNeX vs Conformer
  - Expected: 10-20% improvement
- [ ] Ensemble if both good
  - Average predictions
  - Test-time augmentation
```

**Status:** ‚è≥ Not started  
**Priority:** üü° Medium (after Phase 2 success)  
**Expected Improvement:** 10-20% over EEGNeX baseline

---

## Phase 4: Self-Supervised Pretraining (Weekend) ‚è≥ FUTURE

```markdown
- [ ] Implement EEG-MAE
  - Masked autoencoder for EEG
  - src/models/ssl/eeg_mae.py
- [ ] Pretrain on all HBN data
  - Use labeled + unlabeled subjects
  - ~1000+ subjects total
- [ ] Fine-tune on Challenge 1
  - Load pretrained weights
  - Fine-tune with SAM
- [ ] Compare with from-scratch training
  - Expected: 20-30% improvement
```

**Status:** ‚è≥ Not started  
**Priority:** üü† High (major improvement potential)  
**Expected Improvement:** 20-30% over supervised-only

---

## Phase 5: Ensemble Methods (Next Week) ‚è≥ FUTURE

```markdown
- [ ] Model Soup
  - Average weights from multiple checkpoints
  - Same architecture, different training runs
- [ ] Snapshot Ensembling
  - Cyclic learning rates
  - Save snapshots at local minima
- [ ] Multi-model Ensemble
  - EEGNeX + Conformer + MAE
  - Weighted average predictions
- [ ] Test-Time Augmentation (TTA)
  - Multiple augmented versions
  - Average predictions
```

**Status:** ‚è≥ Not started  
**Priority:** üü¢ Low (polish for final submission)  
**Expected Improvement:** 5-15% over single model

---

## Phase 6: Final Submission (Before Nov 3) ‚è≥ FUTURE

```markdown
- [ ] Select best model/ensemble
- [ ] Create final submission package
- [ ] Write 2-page method description
  - Architecture details
  - Training procedure
  - Results & analysis
- [ ] Final local validation
- [ ] Upload to Codabench
- [ ] Monitor leaderboard
- [ ] Submit paper if required
```

**Status:** ‚è≥ Not started  
**Deadline:** November 3, 2025 (9 days remaining)  
**Priority:** üî¥ Critical (final deliverable)

---

## Immediate Action Items (Next 4 Hours)

### Now (17:05 UTC)
1. ‚úÖ Training running in tmux (crash-proof)
2. ‚úÖ Documentation created
3. ‚úÖ Monitor scripts ready

### In 30 minutes (17:35 UTC)
1. Check if data loading complete: `./monitor_training.sh`
2. Verify first epoch started
3. Check GPU utilization: `rocm-smi`

### In 1 hour (18:05 UTC)
1. Check epoch progress (should be ~5-10 epochs done)
2. Verify NRMSE decreasing
3. Confirm no errors/crashes

### In 3 hours (20:05 UTC)
1. Check if early stopping triggered
2. If complete, analyze results
3. If not, continue monitoring

### Tonight/Tomorrow Morning
1. Training should be complete
2. Analyze final results
3. Create submission if successful
4. Upload to Codabench

---

## Success Metrics

### Phase 2 Success (Current Phase)
- ‚úÖ Training completes without crashes ‚Üí **ACHIEVED (tmux)**
- [ ] Validation NRMSE < 0.30 ‚Üí **PENDING**
- [ ] Test NRMSE < 1.0 ‚Üí **PENDING**

### Overall Competition Success
- [ ] Challenge 1 NRMSE < 1.0 ‚Üí Target
- [ ] Challenge 2 NRMSE < 1.5 ‚Üí Target
- [ ] Overall NRMSE < 1.25 ‚Üí Target
- [ ] Top 100 on leaderboard ‚Üí Stretch Goal

---

## Risk Mitigation

### Risks Identified
1. ~~VSCode crashes~~ ‚Üí ‚úÖ SOLVED (tmux)
2. ~~Training not starting~~ ‚Üí ‚úÖ SOLVED (working data loader)
3. NRMSE not improving ‚Üí Mitigate with hyperparameter tuning
4. GPU memory issues ‚Üí Already optimized (batch_size=32)
5. Time running out ‚Üí 9 days remaining, on track

### Contingency Plans
- **If NRMSE > 1.0:** Try different hyperparameters (lower rho, different LR)
- **If training fails:** Use ensemble with Oct 16 weights (1.002 C1)
- **If time tight:** Submit working solution, iterate later
- **If GPU crashes:** Restart in tmux (already set up)

---

## Timeline Summary

| Phase | Status | Start | End | Duration |
|-------|--------|-------|-----|----------|
| Phase 1: Core Components | ‚úÖ Complete | Oct 24 14:00 | Oct 24 15:30 | 1.5h |
| Phase 2A: Crash Recovery | ‚úÖ Complete | Oct 24 16:00 | Oct 24 17:00 | 1h |
| Phase 2B: Training | üîÑ In Progress | Oct 24 17:00 | Oct 24/25 | 3-4h |
| Phase 2C: Analysis | ‚è≥ Pending | TBD | TBD | 0.5h |
| Phase 2D: Submission | ‚è≥ Conditional | TBD | TBD | 1h |
| Phase 3: Advanced Models | ‚è≥ Future | Oct 25/26 | Oct 26/27 | 1-2 days |
| Phase 4: SSL Pretraining | ‚è≥ Future | Oct 26/27 | Oct 28/29 | 2-3 days |
| Phase 5: Ensembles | ‚è≥ Future | Oct 29/30 | Oct 31 | 1-2 days |
| Phase 6: Final Submission | ‚è≥ Future | Nov 1 | Nov 3 | 2-3 days |

**Current Progress:** 30% complete (3 of 10 major phases)  
**On Track:** Yes, 9 days remaining for 70% remaining work  
**Bottleneck:** Waiting for Phase 2B training completion  

---

## Key Files & Locations

### Training
- **Script:** `train_challenge1_advanced.py`
- **Log:** `training_tmux.log`
- **Checkpoints:** `experiments/sam_full_run/20251024_165931/checkpoints/`
- **History:** `experiments/sam_full_run/20251024_165931/history.json`

### Tmux Management
- **Launcher:** `start_training_tmux.sh`
- **Monitor:** `monitor_training.sh`
- **Session:** `eeg_training`

### Documentation
- **Status:** `TMUX_TRAINING_STATUS.md`
- **TODO:** `TODO_PHASE2_OCT24.md` (this file)
- **Test Results:** `TRAINING_SUCCESS.md`
- **Investigation:** `PHASE2_STATUS.md`

### Previous Work
- **Oct 16 Baseline:** `weights/weights_challenge_1_20251016.pt`
- **Submission Package:** `submission_fixed.zip`
- **Leaderboard:** C1: 1.002, C2: 1.460, Overall: 1.322

---

## Notes & Observations

### What's Working
1. ‚úÖ Tmux for crash resistance
2. ‚úÖ Working data loader (manual RT extraction)
3. ‚úÖ SAM optimizer (12.9% improvement in test)
4. ‚úÖ Subject-level CV (no data leakage)
5. ‚úÖ Advanced augmentation
6. ‚úÖ AMD ROCm GPU support (5.98 GB VRAM)

### What We Learned
1. **nohup is not enough** - VSCode crashes still kill processes
2. **tmux is industry standard** - Survives any disconnect
3. **Data loading takes time** - 334 subjects = 5-10 minutes
4. **Test early** - 2 epoch test saved us from training failures
5. **Document everything** - Status reports critical for recovery

### What's Next
1. **Wait for training** - Let tmux do its job (2-4 hours)
2. **Analyze results** - Once complete, check NRMSE
3. **Create submission** - If good, package and upload
4. **Advanced models** - Weekend work if Phase 2 succeeds
5. **Iterate** - Keep improving until Nov 3 deadline

---

**Last Updated:** October 24, 2025 17:05 UTC  
**Next Update:** After data loading completes (~17:35 UTC)  
**Status:** ‚úÖ TRAINING IN TMUX - CRASH PROOF  

---

## Quick Reference

### Check Training Status
```bash
./monitor_training.sh
```

### Watch Live Output
```bash
tail -f training_tmux.log
```

### Attach to Session
```bash
tmux attach -t eeg_training
# Detach: Ctrl+B then D
```

### Check GPU
```bash
rocm-smi
```

### Restart if Needed
```bash
./start_training_tmux.sh
```

---

**üéØ CURRENT FOCUS:** Waiting for data loading to complete, then monitor training progress for next 3-4 hours.
